{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7cebd68-cd01-43ee-ac1d-ac9efcfc6375",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gym\n",
    "import numpy as np\n",
    "from IPython import display\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "from envs import Maze\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1dd4993-02f3-4c1f-8918-a3b4d08c5176",
   "metadata": {},
   "source": [
    "## Quick view of the Gym library:\r\n",
    "\r\n",
    "#### Gym is a library for reinforcement learning research. It provides us with a simple interface to a large number of tasks, including\r\n",
    "<br>\r\n",
    "-\r\n",
    "Classic control tasks (CartPole, Pendulum, MountainCar, et\r\n",
    "<br>c- )\r\n",
    "Classic video games (Space Invaders, Breakout, Pong, e\r\n",
    "<br>\r\n",
    "- c)\r\n",
    "Continuous control t.a<br>\r\n",
    "- sks\r\n",
    "Robotic arm manipul.\r\n",
    "\r\n",
    "![title](img/mdp_diagram.svg)ation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8de4142a-81a4-4f6e-8002-d2bb004db9af",
   "metadata": {},
   "source": [
    "#### Making the environment: Maze()\r\n",
    "\r\n",
    "To create an environment, just pass a string with its name to the gym.make method. If the environment exists, the method returns an instance of the gym.Env class, which represents the environment of the task we are going to solve."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954536a8-e63e-4d3e-a26d-b9ac31180f2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "env = Maze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddeeab7a-f7cc-4742-a509-f1f401d4aca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### env.reset()\n",
    "\n",
    "This method places the environment in its initial state to  and returns it so that the agent can observe it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61efb12d-654b-4a4c-89f1-d8d6a1810525",
   "metadata": {},
   "outputs": [],
   "source": [
    "initial_state = env.reset()\n",
    "print(f\"The new episode will start in state: {initial_state}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0befdc3d-998c-4089-bc9d-7fe4bea8b6b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### env.render()\n",
    "\n",
    "This method generates an image that represents the current state of the environment, in the form of a np.ndarray."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "565cb2b7-6be0-4c3f-815c-1c866c88931e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = env.render(mode='rgb_array')\n",
    "plt.axis('off')\n",
    "plt.title(f\"State: {initial_state}\")\n",
    "plt.imshow(frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8d3d93d-ab56-4a9e-9fa0-431ace878a21",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### env.step()\n",
    "\n",
    "This method applies the action selected by the agent in the environment, to modify it. In response, the environment returns a tuple of four objects:\n",
    "\n",
    "- The next state\n",
    "- The reward obtained\n",
    "- (bool) if the task has been completed\n",
    "- any other relevant information in a python dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d5216de-88ef-4b6f-bcc5-c40de1ad2dd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "action = 2\n",
    "next_state, reward, done, info = env.step(action)\n",
    "print(f\"After moving down 1 row, the agent is in state: {next_state}\")\n",
    "print(f\"After moving down 1 row, we got a reward of: {reward}\")\n",
    "print(\"After moving down 1 row, the task is\", \"\" if done else \"not\", \"finished\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebb8c786-7dee-4af2-8ab8-bd969577ea8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Render the new state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "072cbd60-b51a-4073-8def-d15a7f5fbaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "frame = env.render(mode='rgb_array')\n",
    "plt.axis('off')\n",
    "plt.title(f\"State: {next_state}\")\n",
    "plt.imshow(frame)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
